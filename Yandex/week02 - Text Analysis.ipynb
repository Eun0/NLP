{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script demonstrates Large scale text analysis with deep learning\n",
    "\n",
    "## Name : Eun-Yeong Jeon\n",
    "\n",
    "## github : https://github.com/Eun0/NLP/tree/master/Yandex\n",
    "\n",
    "## sources : https://github.com/yandexdataschool/nlp_course/blob/master/week02_classification/seminar.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task :\n",
    "\n",
    "Predicting job salary by using deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline :\n",
    "\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages for plotting graphs and manipulating data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data :\n",
    "\n",
    "kaggle data,\n",
    "\n",
    "you can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction/data)\n",
    "\n",
    "if you are first time, remove the comment (#)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0  119M    0  463k    0     0   203k      0  0:10:03  0:00:02  0:10:01  846k\n",
      "  7  119M    7 8623k    0     0  2615k      0  0:00:46  0:00:03  0:00:43 5520k\n",
      " 15  119M   15 18.7M    0     0  4487k      0  0:00:27  0:00:04  0:00:23 7544k\n",
      " 24  119M   24 29.2M    0     0  5661k      0  0:00:21  0:00:05  0:00:16 8430k\n",
      " 32  119M   32 39.1M    0     0  6377k      0  0:00:19  0:00:06  0:00:13 8810k\n",
      " 39  119M   39 47.5M    0     0  6681k      0  0:00:18  0:00:07  0:00:11 9638k\n",
      " 47  119M   47 57.0M    0     0  7025k      0  0:00:17  0:00:08  0:00:09 9923k\n",
      " 57  119M   57 68.2M    0     0  7531k      0  0:00:16  0:00:09  0:00:07  9.9M\n",
      " 65  119M   65 78.5M    0     0  7795k      0  0:00:15  0:00:10  0:00:05  9.8M\n",
      " 71  119M   71 85.9M    0     0  7797k      0  0:00:15  0:00:11  0:00:04 9580k\n",
      " 80  119M   80 96.3M    0     0  8035k      0  0:00:15  0:00:12  0:00:03  9.7M\n",
      " 89  119M   89  107M    0     0  8281k      0  0:00:14  0:00:13  0:00:01 10.1M\n",
      " 98  119M   98  117M    0     0  8415k      0  0:00:14  0:00:14 --:--:--  9.8M\n",
      "100  119M  100  119M    0     0  8475k      0  0:00:14  0:00:14 --:--:--  9.9M\n",
      "x Train_rev1.csv\n"
     ]
    }
   ],
   "source": [
    "#!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "#!tar -xvzf ./Train_rev1.csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "224768 sample data with 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244768 entries, 0 to 244767\n",
      "Data columns (total 12 columns):\n",
      "Id                    244768 non-null int64\n",
      "Title                 244767 non-null object\n",
      "FullDescription       244768 non-null object\n",
      "LocationRaw           244768 non-null object\n",
      "LocationNormalized    244768 non-null object\n",
      "ContractType          65442 non-null object\n",
      "ContractTime          180863 non-null object\n",
      "Company               212338 non-null object\n",
      "Category              244768 non-null object\n",
      "SalaryRaw             244768 non-null object\n",
      "SalaryNormalized      244768 non-null int64\n",
      "SourceName            244767 non-null object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem : Oddly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with salary prediction is that it's oddly distributed\n",
    "\n",
    "The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8, 4])\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several techniques to combat this :\n",
    "\n",
    "1. Using different loss function\n",
    "\n",
    "2. Predicting log-target instead of raw target\n",
    "\n",
    "3. Replacing targets with their percentiles among all salaries in the training set\n",
    "\n",
    "We gonna use __logarithm__ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add 'Log1pSalary' column\n",
    "\n",
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to predict one number,__Log1pSalary__\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "\n",
    "- Free text : __Title__ , __FullDescription__\n",
    "\n",
    "- Categorical : __Category__, __Company__, __LocationNormalized__, __ContractType__, __ContractTime__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling null values :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Title__, __ContractType__, __ContractTime__, __Company__, __SourceName__ columns have null values\n",
    "\n",
    "Use ```pandas.fillna(replacement)``` to remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "Title                      1\n",
       "FullDescription            0\n",
       "LocationRaw                0\n",
       "LocationNormalized         0\n",
       "ContractType          179326\n",
       "ContractTime           63905\n",
       "Company                32430\n",
       "Category                   0\n",
       "SalaryRaw                  0\n",
       "SalaryNormalized           0\n",
       "SourceName                 1\n",
       "Log1pSalary                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    0\n",
       "Title                 0\n",
       "FullDescription       0\n",
       "LocationRaw           0\n",
       "LocationNormalized    0\n",
       "ContractType          0\n",
       "ContractTime          0\n",
       "Company               0\n",
       "Category              0\n",
       "SalaryRaw             0\n",
       "SalaryNormalized      0\n",
       "SourceName            1\n",
       "Log1pSalary           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Title']=data['Title'].fillna('')\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show sample data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>61584796</td>\n",
       "      <td>Door to Door Fundraiser, Weekly Basic Rate  Bonus</td>\n",
       "      <td>Door to Door Fundraiser, Weekly Basic Rate  Bo...</td>\n",
       "      <td>North East</td>\n",
       "      <td>North East England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sales Jobs</td>\n",
       "      <td>10k - 15k</td>\n",
       "      <td>12500</td>\n",
       "      <td>simplysalesjobs.co.uk</td>\n",
       "      <td>9.433564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55935</th>\n",
       "      <td>68681172</td>\n",
       "      <td>Quality Administrator</td>\n",
       "      <td>Our client a major independent research organi...</td>\n",
       "      <td>Chipping Campden Gloucestershire South West</td>\n",
       "      <td>Chipping Campden</td>\n",
       "      <td>part_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rainbow Recruit</td>\n",
       "      <td>Admin Jobs</td>\n",
       "      <td>Upto 16,000 per annum Pro rata</td>\n",
       "      <td>16000</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>9.680407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124295</th>\n",
       "      <td>69969123</td>\n",
       "      <td>Marketing Associate</td>\n",
       "      <td>As the Marketing Associate you will have full ...</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMR</td>\n",
       "      <td>Accounting &amp; Finance Jobs</td>\n",
       "      <td>up to 35,000</td>\n",
       "      <td>35000</td>\n",
       "      <td>eFinancialCareers</td>\n",
       "      <td>10.463132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "4386    61584796  Door to Door Fundraiser, Weekly Basic Rate  Bonus   \n",
       "55935   68681172                              Quality Administrator   \n",
       "124295  69969123                                Marketing Associate   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "4386    Door to Door Fundraiser, Weekly Basic Rate  Bo...   \n",
       "55935   Our client a major independent research organi...   \n",
       "124295  As the Marketing Associate you will have full ...   \n",
       "\n",
       "                                        LocationRaw  LocationNormalized  \\\n",
       "4386                                     North East  North East England   \n",
       "55935   Chipping Campden Gloucestershire South West    Chipping Campden   \n",
       "124295                                       London              London   \n",
       "\n",
       "       ContractType ContractTime          Company                   Category  \\\n",
       "4386            NaN    permanent              NaN                 Sales Jobs   \n",
       "55935     part_time          NaN  Rainbow Recruit                 Admin Jobs   \n",
       "124295          NaN          NaN              EMR  Accounting & Finance Jobs   \n",
       "\n",
       "                             SalaryRaw  SalaryNormalized  \\\n",
       "4386                         10k - 15k             12500   \n",
       "55935   Upto 16,000 per annum Pro rata             16000   \n",
       "124295                    up to 35,000             35000   \n",
       "\n",
       "                   SourceName  Log1pSalary  \n",
       "4386    simplysalesjobs.co.uk     9.433564  \n",
       "55935           totaljobs.com     9.680407  \n",
       "124295      eFinancialCareers    10.463132  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data part :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this part is to __make data for use in deep learning__ \n",
    "\n",
    "1 . Convert each text columns to (integer) matrix \n",
    "\n",
    "2 . Convert each categorical columns by one-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing text data : \n",
    "\n",
    "Splitting raw text into sequences of tokens (words, punctuation, etc)\n",
    "\n",
    "To do this, we need three steps :\n",
    "\n",
    "1. To lowercase\n",
    "\n",
    "2. Tokenize\n",
    "\n",
    "3. Store the tokenized data as a space-separated string of tokens\n",
    "\n",
    "\n",
    "and Make (integer) matrix by using the vocabulary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show raw text of FullDescription : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing(raw_text) function :\n",
    "\n",
    "Apply above 3 steps to raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 소문자로 바꾸고 토큰화 under Title,FullDescription\n",
    "## 결과를 공백으로 구분된 string으로 저장\n",
    "\n",
    "def preprocessing(raw_text):\n",
    "    \n",
    "    # Set tokenizer\n",
    "    import nltk\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    \n",
    "    # To lowercase\n",
    "    result=''.join(list(map(str.lower,raw_text)))\n",
    "    \n",
    "    # Tokenize\n",
    "    result=tokenizer.tokenize(result)\n",
    "    \n",
    "    # Store data as a space-separated string of tokens\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the raw text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title']=data['Title'].map(lambda x : preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FullDescription']=data['FullDescription'].map(lambda x : preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make word-count vocabulary :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use __Counter__ (in collections packages) to make vocabulary\n",
    "\n",
    "The usage of Counter is as follows\n",
    "\n",
    "Counter returns like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'how', 'are', 'you', 'i', 'am', 'fine', 'thank', 'you']\n",
      "Counter({'you': 2, 'hi': 1, 'how': 1, 'are': 1, 'i': 1, 'am': 1, 'fine': 1, 'thank': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lines=['hi how are you','i am fine thank you']\n",
    "\n",
    "# Split and flatten\n",
    "# why flatten?\n",
    "# if no flatten because split() returns list\n",
    "# , so the result would be list of list\n",
    "\n",
    "res=[y for line in lines for y in line.split()]\n",
    "print(res)\n",
    "\n",
    "print(Counter(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate 'Title' and 'FullDescription' columns :\n",
    "\n",
    "Is it okay?\n",
    "\n",
    "we'll only count the words,so it's okay to concatenate\n",
    "\n",
    "<br>\n",
    "\n",
    "__\\* CAUTION \\*__\n",
    "\n",
    "Because we handle space-separated string of tokens,\n",
    "\n",
    "we have to __insert ' '(blank space)__ in the middle of two cols when using '+' operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a         b\n",
      "0   hiwhy  whatfuck\n",
      "1  niceso     theme\n",
      "         a          b\n",
      "0   hi why  what fuck\n",
      "1  nice so     the me\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "a=pd.DataFrame({'a':['hi','nice'],'b':['what','the']})\n",
    "b=pd.DataFrame({'a':['why','so'],'b':['fuck','me']})\n",
    "\n",
    "print(a+b)\n",
    "print(a+\" \"+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word-count vocabulary : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate two columns\n",
    "title_and_fullD=data['Title']+\" \"+data['FullDescription']\n",
    "\n",
    "## Split and flatten for Counting\n",
    "tokens=[y for line in title_and_fullD for y in line.split()]\n",
    "\n",
    "## Make word-count voca\n",
    "token_counts=Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove infrequent tokens :\n",
    "\n",
    "Filter tokens a list of all tokens that occur at least 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "## tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token in token_counts if token_counts[token]>=min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an inverse token index :\n",
    "\n",
    "A dictionary from token to it's index(int) in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My Code\n",
    "token_to_id={}\n",
    "\n",
    "for token in tokens:\n",
    "    \n",
    "    token_to_id[token]=tokens.index(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make neural network-digestible matrices by using vocabulary we've built :\n",
    "\n",
    "Map text line into integer (padding if necessary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "    \n",
    "    # seq의 최대 길이 구하고\n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    # 맨 처음 패드의 index값으로 채우고\n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        # 단어 길이만큼 matrix row에 할당\n",
    "        # 사전에 없는 단어는 UNK의 index값으로 채움\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Sequences :\n",
    "\n",
    "line 1 ) engineering systems analyst\n",
    "\n",
    "line 2 ) hr assistant\n",
    "\n",
    "line 3 ) senior ec & i engineer\n",
    "\n",
    "<br>\n",
    "\n",
    "maximum length of sequences = 5 (line 3)\n",
    "\n",
    "so matrix : 3 x 5 mat\n",
    "\n",
    "<br>\n",
    "\n",
    "the length of line 1 is 3 \n",
    "\n",
    "so 3 will be filled with index values for the word, 2 will be padded \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK의 index: 0\n",
      "PAD의 index: 1 \n",
      "\n",
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"UNK의 index:\",UNK_IX)\n",
    "print(\"PAD의 index:\",PAD_IX,\"\\n\")\n",
    "# example\n",
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. One-hot encoding for categorical columns :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example , For 'Company' col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The deep learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous__, we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[27645, 29893, 33674,     1,     1,     1,     1],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
       "        [10609, 30412, 17746,    33,  8705, 29157,    65]]),\n",
       " 'FullDescription': array([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451,\n",
       "         32939],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,\n",
       "            82],\n",
       "        [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412,\n",
       "         17746]]),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'Log1pSalary': array([ 9.71154 , 10.463132, 10.71444 ], dtype=float32)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "- Title encoder\n",
    "\n",
    "- Description encoder\n",
    "\n",
    "- Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use Keras Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages for construction of model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
    "    \n",
    "    l_title = L.Input(shape=[None], name=\"Title\")\n",
    "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
    "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
    "    \n",
    "    ## Build your monster!\n",
    "    \n",
    "    hidden1=L.Embedding(n_tokens,hid_size)(l_title)\n",
    "    hidden1=L.Conv1D(32,5,activation='relu')(hidden1)\n",
    "    output_title=L.GlobalMaxPool1D()(hidden1)\n",
    "    \n",
    "    hidden2=L.Embedding(n_tokens,hid_size)(l_descr)\n",
    "    hidden2=L.Conv1D(32,5,activation='relu')(hidden2)\n",
    "    output_descr=L.GlobalMaxPool1D()(hidden2)\n",
    "    \n",
    "    hidden3=L.Dense(hid_size,activation='relu')(l_categ)\n",
    "    output_categ=L.Dense(1)(hidden3)\n",
    "    \n",
    "    concatenate=L.concatenate([output_title,output_descr,output_categ])\n",
    "    output_layer = L.Dense(1)(concatenate)\n",
    "    #output_layer=L.concatenate([output_title,output_descr,output_categ])\n",
    "    # end of your code\n",
    "    \n",
    "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
    "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FullDescription (InputLayer)    (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, None, 64)     2186112     Title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, None, 64)     2186112     FullDescription[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Categorical (InputLayer)        (None, 3768)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 32)     10272       embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 32)     10272       embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 64)           241216      Categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 32)           0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 32)           0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1)            65          dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 65)           0           global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            66          concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,634,115\n",
      "Trainable params: 4,634,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
    "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
    "assert dummy_pred.shape == (100, 1)\n",
    "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 35.0746 - mean_absolute_error: 4.4905 - val_loss: 0.6129 - val_mean_absolute_error: 0.5289\n",
      "Epoch 2/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4550 - mean_absolute_error: 0.4665- ETA: 2s - loss: 0.4831 - mean_a"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10            # definitely too small\n",
    "steps_per_epoch = 100  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n",
    "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    \n",
    "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
    "                    validation_steps=data_val.shape[0] // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results:\n",
      "Mean square error: 0.11178\n",
      "Mean absolute error: 0.24611\n",
      "Val results:\n",
      "Mean square error: 0.11733\n",
      "Mean absolute error: 0.25277\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "        batch_pred = model.predict(batch_x)[:, 0]\n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(model, data_train, name='Train')\n",
    "print_metrics(model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(model, sample, col_name='Title'):\n",
    "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
    "    sample = dict(sample)\n",
    "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
    "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
    "\n",
    "    for drop_i in range(len(sample_col_tokens)):\n",
    "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
    "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
    "\n",
    "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
    "    diffs = baseline_pred - predictions_drop_one_token\n",
    "    return list(zip(sample_col_tokens, diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display_html\n",
    "\n",
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"\n",
    "             ):\n",
    "    \n",
    "    def get_color_hex(weight):\n",
    "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "    \n",
    "    tokens_html = [\n",
    "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "        for token, weight in tokens_and_weights\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "        \n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FF2424\">sales</span> <span style=\"background-color: #FF0E0E\">specialist</span> <span style=\"background-color: #FF0101\">iv</span> <span style=\"background-color: #FF0101\">access</span> <span style=\"background-color: #0000FF\">and</span> <span style=\"background-color: #FF0404\">infusion</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">representative</span> <span style=\"background-color: #FFFEFE\">medical</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">opportunity</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">industry</span> <span style=\"background-color: #FFFEFE\">leading</span> <span style=\"background-color: #FFFEFE\">manufacturer</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFCFC\">iv</span> <span style=\"background-color: #FFFAFA\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">formally</span> <span style=\"background-color: #FFFEFE\">recognised</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">number</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFD2D2\">market</span> <span style=\"background-color: #FFFEFE\">space</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">our</span> <span style=\"background-color: #FFFEFE\">client</span> <span style=\"background-color: #FFFEFE\">are</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFD8D8\">ethical</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">dynamic</span> <span style=\"background-color: #FFFEFE\">organisation</span> <span style=\"background-color: #FFFEFE\">absolutely</span> <span style=\"background-color: #FFFEFE\">committed</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">advancement</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">innovative</span> <span style=\"background-color: #FFFEFE\">technologies</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FFFEFE\">title</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFF8F8\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">medication</span> <span style=\"background-color: #FFFEFE\">delivery</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFE6E6\">to</span> <span style=\"background-color: #FEFEFF\">:</span> <span style=\"background-color: #FFB0B0\">iv</span> <span style=\"background-color: #FCFCFF\">teams</span> <span style=\"background-color: #FCFCFF\">,</span> <span style=\"background-color: #FFBCBC\">infection</span> <span style=\"background-color: #FFE0E0\">control</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">lead</span> <span style=\"background-color: #FFFEFE\">intensive</span> <span style=\"background-color: #FFFEFE\">care</span> <span style=\"background-color: #FFF6F6\">nurse</span> <span style=\"background-color: #FFFEFE\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #FFFEFE\">managers</span> <span style=\"background-color: #FFFEFE\">territory</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">location</span> <span style=\"background-color: #FFF8F8\">:</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">package</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFEEEE\">basic</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FEFEFF\">****</span> <span style=\"background-color: #FEFEFF\">k</span> <span style=\"background-color: #FEFEFF\">****</span> <span style=\"background-color: #FEFEFF\">k</span> <span style=\"background-color: #FFFAFA\">,</span> <span style=\"background-color: #FFE8E8\">uncapped</span> <span style=\"background-color: #FFFEFE\">bonus</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFAFA\">addition</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFE0E0\">full</span> <span style=\"background-color: #FFFEFE\">corporate</span> <span style=\"background-color: #FFFEFE\">benefits</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">information</span> <span style=\"background-color: #FFFEFE\">hugely</span> <span style=\"background-color: #FFD6D6\">ethical</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">professional</span> <span style=\"background-color: #FFFEFE\">global</span> <span style=\"background-color: #FFFEFE\">organisation</span> <span style=\"background-color: #FFFCFC\">extremely</span> <span style=\"background-color: #FFFEFE\">well</span> <span style=\"background-color: #FFFEFE\">established</span> <span style=\"background-color: #F8F8FF\">in</span> <span style=\"background-color: #F8F8FF\">the</span> <span style=\"background-color: #F8F8FF\">uk</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #F8F8FF\">market</span> <span style=\"background-color: #FFFEFE\">leader</span> <span style=\"background-color: #FFFEFE\">across</span> <span style=\"background-color: #FAFAFF\">all</span> <span style=\"background-color: #FAFAFF\">of</span> <span style=\"background-color: #FFE8E8\">their</span> <span style=\"background-color: #FEFEFF\">core</span> <span style=\"background-color: #FAFAFF\">business</span> <span style=\"background-color: #FFFEFE\">areas</span> <span style=\"background-color: #FFFEFE\">focus</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">providing</span> <span style=\"background-color: #FFFEFE\">cutting</span> <span style=\"background-color: #FFFEFE\">edge</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">along</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">outstanding</span> <span style=\"background-color: #FFF2F2\">service</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">support</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">retain</span> <span style=\"background-color: #FFFEFE\">talented</span> <span style=\"background-color: #FFFEFE\">personnel</span> <span style=\"background-color: #FFFEFE\">by</span> <span style=\"background-color: #FFD6D6\">offering</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">strong</span> <span style=\"background-color: #FFDCDC\">platform</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">career</span> <span style=\"background-color: #FFFEFE\">development</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFAFA\">/</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFE2E2\">the</span> <span style=\"background-color: #FFF0F0\">following</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">least</span> <span style=\"background-color: #FFFEFE\">2</span> <span style=\"background-color: #FFFEFE\">years</span> <span style=\"background-color: #FFFEFE\">medical</span> <span style=\"background-color: #FFFEFE\">device</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFAFA\">candidates</span> <span style=\"background-color: #FFF8F8\">who</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">sold</span> <span style=\"background-color: #FFFEFE\">disposables</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FFFEFE\">consumables</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">similar</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #F3F3FF\">hospitals</span> <span style=\"background-color: #FFE6E6\">would</span> <span style=\"background-color: #F3F3FF\">be</span> <span style=\"background-color: #FFE2E2\">of</span> <span style=\"background-color: #FFE2E2\">particular</span> <span style=\"background-color: #FFFEFE\">interest</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFD8D8\">sold</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #FFFEFE\">hospitals</span> <span style=\"background-color: #FFFEFE\">demonstrable</span> <span style=\"background-color: #FFFEFE\">performance</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">achievements</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">far</span> <span style=\"background-color: #FFFEFE\">personable</span> <span style=\"background-color: #FFD6D6\">,</span> <span style=\"background-color: #FFE8E8\">adaptable</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFEAEA\">willing</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFFEFE\">learn</span> <span style=\"background-color: #FFFEFE\">keen</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">eager</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">success</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFD2D2\">a</span> <span style=\"background-color: #FFF2F2\">degree</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFF4F4\">at</span> <span style=\"background-color: #FFF8F8\">least</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">able</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">show</span> <span style=\"background-color: #DEDEFF\">a</span> <span style=\"background-color: #DEDEFF\">strong</span> <span style=\"background-color: #DEDEFF\">ability</span> <span style=\"background-color: #DEDEFF\">to</span> <span style=\"background-color: #FFF4F4\">learn</span> <span style=\"background-color: #FFFEFE\">role</span> <span style=\"background-color: #FFFEFE\">information</span> <span style=\"background-color: #FFFEFE\">managing</span> <span style=\"background-color: #FFFCFC\">the</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">region</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">across</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFF4F4\">company</span> <span style=\"background-color: #FFFEFE\">'</span> <span style=\"background-color: #FFFEFE\">s</span> <span style=\"background-color: #FFCCCC\">range</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFEAEA\">iv</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFDCDC\">infusion</span> <span style=\"background-color: #FFF2F2\">solutions</span> <span style=\"background-color: #FFFCFC\">portfolio</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFE4E4\">into</span> <span style=\"background-color: #FFFEFE\">lead</span> <span style=\"background-color: #FFFEFE\">intensive</span> <span style=\"background-color: #FFFEFE\">care</span> <span style=\"background-color: #FFFAFA\">nurse</span> <span style=\"background-color: #FFFAFA\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #FFD2D2\">managers</span> <span style=\"background-color: #FFFAFA\">,</span> <span style=\"background-color: #FFA2A2\">iv</span> <span style=\"background-color: #FEFEFF\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FF9E9E\">infection</span> <span style=\"background-color: #FFCACA\">control</span> <span style=\"background-color: #FFFEFE\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFBCBC\">procurement</span> <span style=\"background-color: #FFD2D2\">sales</span> <span style=\"background-color: #FFF8F8\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFE2E2\">infusion</span> <span style=\"background-color: #FFF6F6\">candidates</span> <span style=\"background-color: #DEDEFF\">must</span> <span style=\"background-color: #DEDEFF\">be</span> <span style=\"background-color: #FFDCDC\">eligible</span> <span style=\"background-color: #FFEEEE\">to</span> <span style=\"background-color: #FFF0F0\">work</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">live</span> <span style=\"background-color: #EAEAFF\">in</span> <span style=\"background-color: #EAEAFF\">the</span> <span style=\"background-color: #FFC6C6\">uk</span> <span style=\"background-color: #EAEAFF\">.</span> <span style=\"background-color: #F0F0FF\">please</span> <span style=\"background-color: #FFFEFE\">contact</span> <span style=\"background-color: #FFFEFE\">allan</span> <span style=\"background-color: #FFF8F8\">waller</span> <span style=\"background-color: #FCFCFF\">on</span> <span style=\"background-color: #F3F3FF\">****</span> <span style=\"background-color: #F3F3FF\">****</span> <span style=\"background-color: #F3F3FF\">****</span> <span style=\"background-color: #F8F8FF\">or</span> <span style=\"background-color: #FFFEFE\">please</span> <span style=\"background-color: #FFFEFE\">hit</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">apply</span> <span style=\"background-color: #FFFEFE\">button</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FFFEFE\">was</span> <span style=\"background-color: #FFFEFE\">originally</span> <span style=\"background-color: #FFFEFE\">posted</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">www</span> <span style=\"background-color: #FFF6F6\">.</span> <span style=\"background-color: #F6F6FF\">salestarget</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #FFCACA\">co</span> <span style=\"background-color: #FFFAFA\">.</span> <span style=\"background-color: #F2F2FF\">uk</span> <span style=\"background-color: #FFEEEE\">/</span> <span style=\"background-color: #FFFAFA\">jobseeking</span> <span style=\"background-color: #FFEAEA\">/</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">****</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 36605\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Computed output size would be negative: -2 [input_size: 2, effective_filter_size: 5, stride: 1]\n\t [[{{node conv1d_21/convolution/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_21/convolution/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1d_21/convolution/ExpandDims_1)]]\n\t [[{{node dense_30/BiasAdd/_991}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_99_dense_30/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-5c5e6d238ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12077\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokens_and_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens_and_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_style\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'font-size:20px;'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokens_and_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FullDescription\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-67284f952811>\u001b[0m in \u001b[0;36mexplain\u001b[1;34m(model, sample, col_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                    for i, tok in enumerate(sample_col_tokens)) \n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;33m*\u001b[0m\u001b[0mpredictions_drop_one_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_drop_one_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mdiffs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseline_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpredictions_drop_one_token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_col_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Computed output size would be negative: -2 [input_size: 2, effective_filter_size: 5, stride: 1]\n\t [[{{node conv1d_21/convolution/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_21/convolution/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1d_21/convolution/ExpandDims_1)]]\n\t [[{{node dense_30/BiasAdd/_991}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_99_dense_30/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "i = 12077\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 227536\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Computed output size would be negative: -1 [input_size: 3, effective_filter_size: 5, stride: 1]\n\t [[{{node conv1d_21/convolution/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_21/convolution/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1d_21/convolution/ExpandDims_1)]]\n\t [[{{node dense_30/BiasAdd/_991}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_99_dense_30/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-c658062defc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Salary (gbp):\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokens_and_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Computed output size would be negative: -1 [input_size: 3, effective_filter_size: 5, stride: 1]\n\t [[{{node conv1d_21/convolution/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_21/convolution/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1d_21/convolution/ExpandDims_1)]]\n\t [[{{node dense_30/BiasAdd/_991}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_99_dense_30/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print(\"Index:\", i)\n",
    "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
